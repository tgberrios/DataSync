# ğŸ—ï¸ Arquitectura Perfecta para CDC - Plan de ImplementaciÃ³n

## ğŸ“‹ Resumen Ejecutivo

Este plan propone una arquitectura unificada y optimizada para Change Data Capture (CDC) que:

- âœ… Soporta **TODAS las tablas** (con PK y sin PK)
- âœ… Usa **triggers** como mecanismo Ãºnico de captura
- âœ… Centraliza la creaciÃ³n de `datasync_metadata` **antes del loop**
- âœ… Elimina la necesidad de estrategias OFFSET/PK incremental
- âœ… Garantiza **mÃ¡xima velocidad** y **consistencia**

---

## ğŸ¯ Objetivos Principales

1. **Universalidad**: CDC para todas las tablas, independientemente de tener PK
2. **Eficiencia**: Una sola creaciÃ³n de infraestructura CDC al inicio
3. **Consistencia**: Mismo comportamiento en MariaDB, MSSQL y Oracle
4. **Performance**: Captura completa de `row_data` para evitar N+1 queries
5. **Simplicidad**: Eliminar lÃ³gica condicional compleja

---

## ğŸ›ï¸ Arquitectura Propuesta

### 1. **Infraestructura CDC (`datasync_metadata`)**

#### **MariaDB**

- **UbicaciÃ³n**: Base de datos **GLOBAL** (una sola para todo el servidor)
- **RazÃ³n**: MariaDB permite acceso cross-database, mÃ¡s eficiente y centralizado
- **CreaciÃ³n**: **ANTES del loop**, una sola vez
- **Estructura**:
  ```sql
  CREATE DATABASE IF NOT EXISTS datasync_metadata;
  CREATE TABLE IF NOT EXISTS datasync_metadata.ds_change_log (
    change_id BIGINT UNSIGNED AUTO_INCREMENT PRIMARY KEY,
    change_time DATETIME DEFAULT CURRENT_TIMESTAMP,
    operation CHAR(1) NOT NULL,
    schema_name VARCHAR(255) NOT NULL,
    table_name VARCHAR(255) NOT NULL,
    pk_values JSON NOT NULL,        -- Para tablas con PK: valores PK
                                    -- Para tablas sin PK: hash de todos los campos
    row_data JSON NOT NULL,         -- SIEMPRE completo (evita N+1)
    INDEX idx_table_time (schema_name, table_name, change_time),
    INDEX idx_table_change (schema_name, table_name, change_id)
  ) ENGINE=InnoDB;
  ```

#### **MSSQL**

- **UbicaciÃ³n**: Schema **dentro de cada base de datos** (uno por database)
- **RazÃ³n**: MSSQL requiere contexto de base de datos, no permite acceso cross-database fÃ¡cil
- **CreaciÃ³n**: **ANTES del loop**, pero para cada base de datos Ãºnica
- **Estructura**:

  ```sql
  -- Por cada base de datos Ãºnica
  USE [database_name];
  IF NOT EXISTS (SELECT * FROM sys.schemas WHERE name = 'datasync_metadata')
    CREATE SCHEMA datasync_metadata;

  CREATE TABLE datasync_metadata.ds_change_log (
    change_id BIGINT IDENTITY(1,1) PRIMARY KEY,
    change_time DATETIME DEFAULT GETDATE(),
    operation CHAR(1) NOT NULL,
    schema_name NVARCHAR(255) NOT NULL,
    table_name NVARCHAR(255) NOT NULL,
    pk_values NVARCHAR(MAX) NOT NULL,  -- JSON como string
    row_data NVARCHAR(MAX) NOT NULL,    -- JSON como string, SIEMPRE completo
    INDEX idx_table_time (schema_name, table_name, change_time),
    INDEX idx_table_change (schema_name, table_name, change_id)
  );
  ```

#### **Oracle**

- **Ya implementado correctamente**: Schema `datasync_metadata` con usuario dedicado
- **Mantener como estÃ¡**

---

### 2. **Triggers para TODAS las Tablas**

#### **Estrategia para Tablas CON PK**

- **`pk_values`**: JSON con valores de las columnas PK
- **`row_data`**: JSON completo con TODOS los campos (evita N+1)
- **IdentificaciÃ³n**: Usar PK para upsert/delete en PostgreSQL

#### **Estrategia para Tablas SIN PK**

- **`pk_values`**: JSON con **hash MD5/SHA256 de todos los campos concatenados**
  - Ejemplo: `{"_hash": "a1b2c3d4..."}`
  - Alternativa: JSON con todos los campos como "PK compuesto"
- **`row_data`**: JSON completo con TODOS los campos
- **IdentificaciÃ³n**: Usar hash o comparaciÃ³n completa de `row_data` en PostgreSQL

#### **Ventajas de esta Estrategia**

1. âœ… **UnificaciÃ³n**: Mismo flujo para todas las tablas
2. âœ… **Performance**: `row_data` completo elimina N+1 queries
3. âœ… **Confiabilidad**: Hash garantiza identificaciÃ³n Ãºnica para tablas sin PK
4. âœ… **Simplicidad**: No mÃ¡s lÃ³gica condicional OFFSET vs PK

---

### 3. **Flujo de Procesamiento CDC**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 1. setupTableTarget*ToPostgres()                       â”‚
â”‚    â”œâ”€ Crear datasync_metadata (ANTES del loop)         â”‚
â”‚    â””â”€ Para cada tabla:                                 â”‚
â”‚       â”œâ”€ Crear triggers (CON PK o SIN PK)              â”‚
â”‚       â””â”€ Capturar cambios en ds_change_log              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 2. processTableCDC()                                    â”‚
â”‚    â”œâ”€ Leer ds_change_log (ORDER BY change_id)          â”‚
â”‚    â”œâ”€ Procesar batch de cambios                        â”‚
â”‚    â”œâ”€ Para INSERT/UPDATE:                              â”‚
â”‚    â”‚   â””â”€ Usar row_data completo (sin N+1)            â”‚
â”‚    â”œâ”€ Para DELETE:                                     â”‚
â”‚    â”‚   â””â”€ Usar pk_values (o hash para sin PK)          â”‚
â”‚    â””â”€ Actualizar last_change_id                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ”§ Cambios TÃ©cnicos Requeridos

### **Fase 1: ReorganizaciÃ³n de CreaciÃ³n de `datasync_metadata`**

#### **MariaDB**

- âœ… Mover `CREATE DATABASE datasync_metadata` **ANTES del loop**
- âœ… Crear una sola vez al inicio del mÃ©todo
- âœ… Usar conexiÃ³n dedicada o primera conexiÃ³n disponible

#### **MSSQL**

- âœ… Ya estÃ¡ correcto (antes del loop)
- âœ… Mejorar para crear por cada base de datos Ãºnica (no solo la primera)
- âœ… Agrupar tablas por base de datos y crear schema una vez por database

### **Fase 2: Triggers para Tablas SIN PK**

#### **MariaDB - Trigger para Tabla SIN PK**

```sql
-- Para INSERT
CREATE TRIGGER ds_tr_schema_table_ai
AFTER INSERT ON schema.table
FOR EACH ROW
INSERT INTO datasync_metadata.ds_change_log
(operation, schema_name, table_name, pk_values, row_data)
VALUES (
  'I',
  'schema',
  'table',
  JSON_OBJECT('_hash', MD5(CONCAT_WS('|', col1, col2, col3, ...))),
  JSON_OBJECT('col1', NEW.col1, 'col2', NEW.col2, ...)
);

-- Para UPDATE
CREATE TRIGGER ds_tr_schema_table_au
AFTER UPDATE ON schema.table
FOR EACH ROW
INSERT INTO datasync_metadata.ds_change_log
(operation, schema_name, table_name, pk_values, row_data)
VALUES (
  'U',
  'schema',
  'table',
  JSON_OBJECT('_hash', MD5(CONCAT_WS('|', NEW.col1, NEW.col2, ...))),
  JSON_OBJECT('col1', NEW.col1, 'col2', NEW.col2, ...)
);

-- Para DELETE
CREATE TRIGGER ds_tr_schema_table_ad
AFTER DELETE ON schema.table
FOR EACH ROW
INSERT INTO datasync_metadata.ds_change_log
(operation, schema_name, table_name, pk_values, row_data)
VALUES (
  'D',
  'schema',
  'table',
  JSON_OBJECT('_hash', MD5(CONCAT_WS('|', OLD.col1, OLD.col2, ...))),
  JSON_OBJECT('col1', OLD.col1, 'col2', OLD.col2, ...)
);
```

#### **MSSQL - Trigger para Tabla SIN PK**

```sql
-- Similar pero usando CONCAT y HASHBYTES('MD5', ...)
-- O usar todos los campos como "PK compuesto" en JSON
```

### **Fase 3: Procesamiento CDC para Tablas SIN PK**

#### **Modificar `processTableCDC()`**

- âœ… Detectar si `pk_values` contiene `_hash` (tabla sin PK)
- âœ… Para tablas sin PK:
  - **INSERT/UPDATE**: Usar `row_data` completo para UPSERT
  - **DELETE**: Usar hash de `row_data` para identificar y eliminar
- âœ… Mantener lÃ³gica actual para tablas con PK

---

## ğŸ“Š ComparaciÃ³n: Antes vs DespuÃ©s

| Aspecto               | Antes                                | DespuÃ©s                         |
| --------------------- | ------------------------------------ | ------------------------------- |
| **Tablas con PK**     | âœ… CDC con triggers                  | âœ… CDC con triggers             |
| **Tablas sin PK**     | âŒ Sin CDC (solo FULL_LOAD + OFFSET) | âœ… CDC con triggers (hash)      |
| **CreaciÃ³n metadata** | Dentro del loop                      | Antes del loop                  |
| **N+1 queries**       | âš ï¸ Posible si row_data NULL          | âœ… Eliminado (siempre completo) |
| **Estrategias**       | CDC, OFFSET, PK                      | âœ… Solo CDC (universal)         |
| **Complejidad**       | Alta (lÃ³gica condicional)            | Baja (un solo flujo)            |

---

## ğŸ¯ Beneficios de esta Arquitectura

### **1. Universalidad**

- âœ… **Todas las tablas** tienen CDC, sin excepciones
- âœ… Mismo comportamiento para PK y no-PK
- âœ… Elimina necesidad de estrategias OFFSET

### **2. Performance**

- âœ… **MÃ¡xima velocidad**: Solo consulta `ds_change_log` (tabla pequeÃ±a)
- âœ… **Sin N+1**: `row_data` siempre completo
- âœ… **Escalable**: Independiente del tamaÃ±o de tablas fuente

### **3. Simplicidad**

- âœ… **Un solo flujo**: CDC para todo
- âœ… **Menos cÃ³digo**: Eliminar lÃ³gica OFFSET/PK incremental
- âœ… **Mantenible**: Menos casos edge, menos bugs

### **4. Consistencia**

- âœ… Mismo patrÃ³n en todos los motores
- âœ… Mismo comportamiento para todas las tablas
- âœ… Predictible y confiable

---

## ğŸš€ Plan de ImplementaciÃ³n

### **Paso 1: Reorganizar CreaciÃ³n de `datasync_metadata`**

- [ ] MariaDB: Mover creaciÃ³n antes del loop
- [ ] MSSQL: Mejorar para crear por cada database Ãºnica
- [ ] Verificar Oracle (ya correcto)

### **Paso 2: Implementar Triggers para Tablas SIN PK**

- [ ] MariaDB: Generar triggers con hash MD5
- [ ] MSSQL: Generar triggers con hash o PK compuesto
- [ ] Probar con tablas reales sin PK

### **Paso 3: Modificar `processTableCDC()`**

- [ ] Detectar tablas sin PK (por `_hash` en `pk_values`)
- [ ] Implementar lÃ³gica de upsert/delete usando hash
- [ ] Mantener compatibilidad con tablas con PK

### **Paso 4: Testing y ValidaciÃ³n**

- [ ] Probar con tablas con PK
- [ ] Probar con tablas sin PK
- [ ] Validar performance
- [ ] Verificar que no hay regresiones

### **Paso 5: Limpieza (Opcional)**

- [ ] Eliminar cÃ³digo OFFSET obsoleto (si aÃºn existe)
- [ ] Simplificar lÃ³gica condicional
- [ ] Actualizar documentaciÃ³n

---

## âš ï¸ Consideraciones Importantes

### **1. Hash para Tablas SIN PK**

- **MD5 vs SHA256**: MD5 es mÃ¡s rÃ¡pido, SHA256 mÃ¡s seguro
- **RecomendaciÃ³n**: MD5 es suficiente para identificaciÃ³n (no seguridad)
- **Alternativa**: Usar todos los campos como "PK compuesto" en JSON

### **2. Performance de Hash**

- **Impacto**: MÃ­nimo, solo en triggers (INSERT/UPDATE/DELETE)
- **Overhead**: < 1ms por operaciÃ³n
- **Beneficio**: CDC universal vale la pena

### **3. Colisiones de Hash**

- **Probabilidad**: Extremadamente baja (1 en 2^128 para MD5)
- **MitigaciÃ³n**: Si ocurre, `row_data` completo permite comparaciÃ³n exacta
- **Riesgo**: PrÃ¡cticamente cero

### **4. MigraciÃ³n de Tablas Existentes**

- **Tablas con PK**: Sin cambios, seguir funcionando igual
- **Tablas sin PK**: Agregar triggers, procesar cambios desde ahora
- **Datos histÃ³ricos**: FULL_LOAD inicial, luego CDC continuo

---

## âœ… Criterios de Ã‰xito

1. âœ… **Todas las tablas** tienen triggers CDC (PK y no-PK)
2. âœ… `datasync_metadata` se crea **una sola vez** antes del loop
3. âœ… **Sin N+1 queries**: `row_data` siempre completo
4. âœ… **Performance**: CDC mÃ¡s rÃ¡pido que OFFSET incremental
5. âœ… **Simplicidad**: Un solo flujo CDC para todo
6. âœ… **Consistencia**: Mismo comportamiento en todos los motores

---

## ğŸ“ Notas Finales

Esta arquitectura:

- ğŸ¯ **Elimina** la necesidad de estrategias OFFSET/PK incremental
- ğŸš€ **Garantiza** mÃ¡xima velocidad con CDC universal
- ğŸ”§ **Simplifica** el cÃ³digo y reduce complejidad
- âœ… **Funciona** para todas las tablas, sin excepciones

**Â¿AprobaciÃ³n para proceder con la implementaciÃ³n?**
